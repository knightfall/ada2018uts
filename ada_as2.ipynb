{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "import itertools\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "print('OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terror = pd.read_csv(\"d:\\\\Work\\\\ADA\\\\gtdb_2000.csv\", low_memory = False, encoding='ISO-8859-1')\n",
    "terror['casualties'] = terror['nkill']+terror['nwound']\n",
    "terror.target1 = terror.target1.str.lower()\n",
    "terror.gname = terror.gname.str.lower()\n",
    "terror.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terror['cas_bin'] = terror['casualties'].apply(lambda x: 0 if x == 0 else 1) #shortcut if else logic to provide true false \n",
    "gtd_pred = ['iyear', \n",
    "            'imonth', \n",
    "            'iday', \n",
    "            'latitude', \n",
    "            'longitude', \n",
    "            'attacktype1',\n",
    "            'region',\n",
    "            'success', \n",
    "            'weaptype1',\n",
    "            'target1',\n",
    "            'INT_LOG',\n",
    "            'INT_IDEO',\n",
    "            'gname', \n",
    "            'property', \n",
    "            'targtype1', \n",
    "            'country']\n",
    "target_pred = 'cas_bin'\n",
    "\n",
    "\n",
    "lb = preprocessing.LabelEncoder()\n",
    "terror['gname'] = lb.fit_transform(terror['gname'])\n",
    "terror['target1'] = lb.fit_transform(terror['target1'])\n",
    "x = terror[gtd_pred].fillna(0)\n",
    "y = terror[target_pred]\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators = 250, random_state = 0)\n",
    "forest.fit(x, y)\n",
    "importance = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n",
    "indices = np.argsort(importance)[::-1]\n",
    "frames = [gtd_pred[i] for i in indices]\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6), dpi=220)\n",
    "plt.bar(range(x.shape[1]), importance[indices],color=\"rgby\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(x.shape[1]), frames, rotation=90)\n",
    "plt.title(\"Prediction of casualty occurance: feature importances\")\n",
    "plt.xlim([-1, x.shape[1]])\n",
    "plt.grid(which='major', linestyle=':', linewidth='0.5', color='red')\n",
    "plt.grid(which='minor', linestyle='-', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtdb_pred_col = ['attacktype1', 'targtype1', 'target1', 'country', 'iday', 'imonth','iyear', 'longitude','latitude']\n",
    "X = terror[gtdb_pred_col].fillna(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4)\n",
    "model = RandomForestClassifier(n_estimators=150)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=False, title='Confusion matrix', cmap=plt.cm.Paired):    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "  \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Original label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    " \n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=220)\n",
    "plot_confusion_matrix(cmatrix,\n",
    "                      title='Confusion matrix - No Normalisation')\n",
    "plt.figure(figsize=(10, 6), dpi=220)\n",
    "plot_confusion_matrix(cmatrix, normalize=True,\n",
    "                      title='Confusion Matrix - Normalised')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall score: %0.2f' % recall_score(y_test, y_pred) )\n",
    "print('Accuracy score: %0.2f' % accuracy_score(y_test, y_pred))\n",
    "print('Precision score: %0.2f' % precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=64)\n",
    "\n",
    "scores = cross_val_score(model, X_train, y_train, cv=20)\n",
    "print('Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes= (10), \n",
    "    activation = 'logistic',\n",
    "    learning_rate = 'adaptive',\n",
    "    learning_rate_init = 0.3,\n",
    "    random_state = 56,\n",
    "    max_iter = 500,    \n",
    "    solver = 'sgd'\n",
    ")\n",
    "\n",
    "mlp_grid = GridSearchCV(mlp, mlp_params, scoring = 'accuracy', cv = 5, n_jobs = -1, error_score= 0)\n",
    "\n",
    "mlp_grid.fit(X_train,y_train)\n",
    "\n",
    "y1_pred = mlp_grid.predict(X_test)\n",
    "\n",
    "print(np.mean(y1_pred == y_test))\n",
    "\n",
    "print(mlp_grid.score(X_test, y_test))\n",
    "print(mlp_grid.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
